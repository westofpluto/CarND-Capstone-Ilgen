### Self-Driving Car Capstone Project - Marc Ilgen
This is the project repo representing my submission for the Capstone Project (the final project for Term 3). While this project was meant to be developed using a team of people, I am a team of one. Why you ask? Well, I got really busy with my real job and got so delayed in looking at the project requirements that by the time I actually started the project, I was already late for submitting it. In short, all the teams had already formed and I was now stuck with doing all the subtasks myself. Lucky me.

In any case, I did indeed get the project up and running successfully and it now drives successfully around the simulator track, stopping appropriately at red lights and starting again when it sees a green light. Here are the specifics of what I accomplished:

* waypoints\_updater: Wrote code to successfully generate waypoints ahead of the vehicle, which act to define the desired trajectory at the current time step. This operates in a closed loop manner so waypoints are repeatedly generated at 10Hz. Note that I needed to drop the waypoint generation frequency from 50Hz to 10Hz to overcome the lag in the simulator with the camera turned on.
* twist\_controller: Wrote the code to successfully control the steering, throttle and brake of the vehicle in response to the desired waypoints. I used a PID controller for the thrust and brake, and the provided yaw_controller for steering control.
* tl\_detector: Wrote code that properly handles traffic lights, i.e., stops at red lights and goes at green lights. It also has logic to slow down when it sees a yellow light (in preparation for turning red). The detector code has two yaml input files, one for the simulator and one for the live site. In the simulator yaml file, it is possible to set "use_ground_truth" to True in order to bypass the camera stoplight classifier (see below) and just use the known ground truth value of the light. In the site file, this variable exists but it makes no difference because at the actual site, the ground truth light information is not avalable to the car.
* tl\_classifier: I implemented code that uses a deep learning classifier based on [SqueezeNet](https://github.com/DeepScale/SqueezeNet) to classify each camera image as either having a red or yellow or green light, or no light at all. My classifier is saved in [a separate github repo here](https://github.com/westofpluto/traffic_light_classifier_ilgen_save). For the simulator, I trained using the data in [Alex Lechner's Traffic Light Classifier repo](https://github.com/alex-lechner/Traffic-Light-Classification). For the site, I used the site data in that repo but I also wrote a python script to augment the data to include expansions, translations, Gaussian noise, etc. This was necessary to get a training database of adequate size. My classifier had well above 90% accuracy for test images in both the simulator and site datasets. I ended up with two separate models for the classifier: one for the simulator and one for the site. During ROS execution, the tl_detector input yaml files have an "is\_site" parameter that is checked so that the proper model can be loaded.

The code runs in a ROS environment. I developed the code on the Udacity-provided Ubuntu VM which I ran in VirtualBox on my MacBook host. I trained the light classifier on a P2-large AWS instance for faster training, then copied the models back to the VM.

For setup and installation instructions, please see the original README file (called README\_original.md in the current repo).
